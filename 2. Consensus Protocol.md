This is Crynux's answer to verifiable compute: a not exactly Proof of Stake but loosely PoS system that relies on consensus to agree on a task's output.

## The Consensus Protocol in a Nutshell

1. When you send a task to the blockchain, three nodes will be chosen at random to execute the same task on similar hardware with the same arguments. 

Sidenote: Although the docs talk about Verifiable Random Functions and Zero Knowledge Proofs ([ref](https://docs.crynux.ai/system-design/vrf-task-sampling)), discussing this as a means to reduce the overhead of validation, *none of this is present in the project as is, nor does it make much sense given that 1) it means not every task is validated properly and 2) the compute cost for ZKP*.

2. Since it is basically impossible to generate identical images without identical hardware (which is recognised by the creators), Crynux uses a "Perceptual Hash" (pHash), followed by a Hamming Distance calculation between pHashes to check for similarity (we will look at the technical implementation later).

3. To prevent gaming by intercepting other nodes results, the pHash and a random number are hashed together as an on-chain commitment first to indicate task completion, and after all submissions, then pHashes will be disclosed for comparison

## Staking and Slashing

This is supposedly not PoS. 

All nodes participating will stake some amount of CNX in order to be deemed eligible to serve as a compute provider. If someone were to act as a malicious node and submit fake results to the network, if this is recognised during the process (e.g. pHash exceeding the Hamming distance threshold), then their CNX will be slashed as a penalty.

Obviously, systems are not failure proof and slashing should be fairly executed. If 2 or more nodes report an error executing the task, the task is aborted and your CNX will not be slashed. If a node goes offline (lets say it crashed), the task can also timeout, in which your CNX will not be retroactively slashed. 

This presents obvious ways to game the system that the creators recognise:
- An attacker waits to become 2 of 3 nodes selected for the same task. If this happens, they can submit a false result via both nodes, screwing over the third node and gaining a reward for a fraudulent result.
- If the above does not occur, an attacker should simply timeout so that it isn't penalized.

There are some [interesting equations](https://docs.crynux.ai/system-design/consensus-protocol) proposed in the docs that seek to reduce the possible profitability of such attacks, with the common conclusion that to mitigate these, the staking amount should be increased over time. Whether this will actually be implemented is to be seen.

For reference, as of right now, you stake a fixed amount of 400 CNX on the testnet.

## Effectiveness

Right now, the Consensus Protocol proposed here is fairly logical, and in an ideal world where there are enough nodes operating and the pHashes work as intended, it would end up being a relatively effective solution to the problem of verifiable compute. 

As previously stated, *actual verifiable compute* is virtually impossible to accomplish as of right now due to the sheer complexity involved in generating Zero Knowledge Proofs for deep learning or the compute cost of Fully Homomorphic Encryption, so a PoS-esque system that hinges on consensus is about as good as you can get at this point.

But now this begs the question: can I game this, and is this scalable?

Here, we see a few holes to poke and prod at:
- How easy is it to spoof a node (that responds with completely fake results)?
	- An attacker can trivially increase the odds of hitting that 2/3 for a computation through sheer volume, with the only cost being the amount needed to stake per node. 
	- If the approach to defeat such an adversary would be to increase the staking amount, how badly are you screwing over legitimate compute providers?
- How easy is it to spoof an inference result?
	- Our consensus algorithm hinges on the effectiveness of the pHashes in verifying output. Is the pHash gameable? Can I get away with a lower compute method?
	- Docs recognise this as a potential issue, to which the response is "as long as the result is similar enough to be accepted by the application, it is fine to the network"
	- Right now, we are working with simpler, older models and small dimensions (512x512). Would such a system continue to work with more advanced models which have even less deterministic results and more complex prompts and larger outputs?
- How easy is it to increase the odds of being chosen as a node?
	- Can you make certain task requests that your nodes are more likely to fulfill?


