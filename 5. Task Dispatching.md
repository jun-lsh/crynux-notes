## Quality of Service

Node quality is evaluated based on:
- VRAM Size
- Setting a shorter timeout
- Having a faster submission speed

And there's [some math](https://docs.crynux.ai/system-design/quality-of-service-qos) that goes along with it

Apparently, the QoS gets actively updated on the fly. This QoS also determines your likelihood of being chosen for a task and your share of token rewards. 

So, how much of this is actually implemented?

Looking at [QOS.sol](https://github.com/crynux-ai/crynux-contracts/blob/main/contracts/QOS.sol) we see that your score is determined by this one array `TASK_SCORE_REWARDS` which awards you more points for being first and less for being last. Also, your score gets zeroed out if your total score is under the `kickoutThreshold`, which is only `20`, so you basically just have to make maybe 4 or 5 good submissions to avoid getting kicked out.

Also, looking at [Task.sol](https://github.com/crynux-ai/crynux-contracts/blob/4c2d5814fd64b04f144009dea4f8e77a5c47e8d2/contracts/Task.sol#L413), QoS is not actually an influencing factor on your odds of being chosen as a provider. Shucks.
## Finding the Right Compute Providers

- When tasks are dispatched, they are graded based on the task type and the VRAM requirement, which filters out GPUs e.g. an intensive image gen task is unlikely to be completed on a laptop RTX 3050 with 4 GB of VRAM.
- Apparently you are also graded by card model? e.g. RTX 4090s are grouped together and RTX 3080s are grouped together. But in the next paragraph it states that it will randomly pick the card model group, so the group with more nodes will have a higher probability of being selected.
- Higher valued tasks are pushed further up the queue. The value of a task is essentially how much a user is willing to pay for the task divided by the task execution time, which is determined... how?
	- The task execution time must be known before the task is executed, so that means it has to be estimated, right?

## "Is any of this actually implemented?"

- It seems like the same GPU flag is only set for the GPT task, which as of right now is basically unusable.
- It does seem like when a task is created, a `vramLimit` is set, which filters out GPUs. This limit is user determined.
- The card grouping does not seem to be implemented at all.
- Task execution time estimation is nowhere to be found. The only determining factor is the task price, which is also user determined. 


## Is this Gameable?

So what if I issue tasks with a minimum VRAM requirement of, like, 64GB, then run a bunch of fake nodes that claim to have that VRAM? If we receive any other tasks, just timeout without much consequence.

No other nodes have that much VRAM, so the task is for sure going to end up with me. 

Using the SDK, we can issue a request with a VRAM limit like that:

![[Fake_Request.png]]

And we simply skip past the actual inference in the node's code and just copy a dummy file:

![[Dummy_Code.png]]

This works!

Here is a [tx](https://bb.dym.fyi/r/dev-crynux/tx/0xf98662e9f600425f93539275b8680864b8de81e5369a5330c5a45385a4b035fb) where I got a payout for a fake task. Great success.

I did screw it up later on, however, and got my stake slashed. For one, at least that logic functions. But on the other hand, we've now proven that a Sybil attack can be performed with the only real cost being the staked tokens!